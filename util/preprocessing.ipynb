{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RdzPT1CtDKlw"},"source":["import numpy as np\n","import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.util import deprecation\n","from sklearn.model_selection import train_test_split\n","deprecation._PRINT_DEPRECATION_WARNINGS = False\n","# import cv2 as cv\n","# from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEzTs-USB-7J","executionInfo":{"status":"ok","timestamp":1608628977876,"user_tz":-60,"elapsed":1609,"user":{"displayName":"Stefano Petrocchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjuWM88lNSdBp6jbflgk3tf7Z59xGL5uCaozXJ=s64","userId":"04681035504309485253"}},"outputId":"2807527b-5b7f-4c11-ab07-807f37ae62a0"},"source":["def load_images_and_lables(img_path, labels_path):\n","  '''\n","  Returns images and labels as np tensor\n","  '''\n","  images = np.load(img_path)\n","  labels = np.load(labels_path)\n","  return images,labels\n","\n","print('\"load_images_and_lables\" function loaded' )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"load_images_and_lables\" function loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mz9Rk1rmFH8A","executionInfo":{"status":"ok","timestamp":1608628979518,"user_tz":-60,"elapsed":1439,"user":{"displayName":"Stefano Petrocchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjuWM88lNSdBp6jbflgk3tf7Z59xGL5uCaozXJ=s64","userId":"04681035504309485253"}},"outputId":"4015c3f7-5867-449c-96e8-436c10854545"},"source":["def preprocess_normalize_images(images, dataset_mean, dataset_std):\n","  '''\n","  As suggested in many papers normalization is done using all trainingset mean \n","  and std, returns images with std = 1, mean = 0 and of type float32\n","  '''\n","  \n","  # Unfortunatelly CLAHE need to be applied one image at time\n","  #clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(4,4)) \n","  #for idx in tqdm(range(len(images))):\n","    #images[idx] = clahe.apply(images[idx])\n","\n","  preprocessed_images = (images - dataset_mean) / dataset_std\n","  preprocessed_images = preprocessed_images.reshape((preprocessed_images.shape[0], 150, 150, 1))\n","  preprocessed_images = preprocessed_images.astype('float32')\n","  return preprocessed_images\n","\n","print('\"preprocess_normalize_images\" function loaded' )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"preprocess_normalize_images\" function loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SgFMr96uSGSa"},"source":["def deprocess_image_to_RGB(x):\n","    '''\n","    Convert back a preprocessed tensor into a valid image\n","    '''\n","\n","    # normalize tensor: center on 0., ensure std is 0.1\n","    x -= x.mean()\n","    x /= (x.std() + 1e-5)\n","    x *= 0.1\n","\n","    # clip to [0, 1]\n","    x += 0.5\n","    x = np.clip(x, 0, 1)\n","\n","    # convert to grayscale array on 8 bit\n","    x *= 256\n","    x = np.clip(x, 0, 256).astype('uint8')\n","    return x\n","\n","print('\"deprocess_image_to_RGB\" function loaded' )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbOppljRGZNf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608628980803,"user_tz":-60,"elapsed":1046,"user":{"displayName":"Stefano Petrocchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjuWM88lNSdBp6jbflgk3tf7Z59xGL5uCaozXJ=s64","userId":"04681035504309485253"}},"outputId":"fdc07650-8780-4588-d207-be27ae74aca4"},"source":["def deprocess_image(x):\n","    '''\n","    Convert back a preprocessed tensor into a valid image\n","    '''\n","\n","    # normalize tensor: center on 0., ensure std is 0.1\n","    x -= x.mean()\n","    x /= (x.std() + 1e-5)\n","    x *= 0.1\n","\n","    # clip to [0, 1]\n","    x += 0.5\n","    x = np.clip(x, 0, 1)\n","\n","    # convert to grayscale array on 16 bit\n","    x *= 65535\n","    x = np.clip(x, 0, 65535).astype('uint16')\n","    return x\n","\n","print('\"deprocess_image\" function loaded' )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"deprocess_image\" function loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MeK2rJl3HqgS","executionInfo":{"status":"ok","timestamp":1608628983873,"user_tz":-60,"elapsed":1080,"user":{"displayName":"Stefano Petrocchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjuWM88lNSdBp6jbflgk3tf7Z59xGL5uCaozXJ=s64","userId":"04681035504309485253"}},"outputId":"6936c766-7e2d-4fd2-8f1e-f302d185aef8"},"source":["datagen = ImageDataGenerator(\n","      horizontal_flip = True,\n","      rotation_range = 30,\n","      zoom_range = [0.75, 1.25],\n","      fill_mode = 'nearest')\n","      #channel_shift_range = 0.2, \n","      #vertical_flip = True)\n","\n","\n","# Parameters from ISMMS\n","'''\n","H e V flip\n","rotation [-25,25]\n","zoom [0.8, 1.2]\n","intensity shift [-20, 20] \n","'''\n","\n","# Parameters from Girona & Manchester\n","'''\n","H flip\n","rotation [-30,30]\n","zoom [0.75, 1.25]\n","'''\n","\n","print('\"datagen\" class loaded' )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"datagen\" class loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfDpii20Iv-0","executionInfo":{"status":"ok","timestamp":1608283187517,"user_tz":-60,"elapsed":735,"user":{"displayName":"Stefano Petrocchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjuWM88lNSdBp6jbflgk3tf7Z59xGL5uCaozXJ=s64","userId":"04681035504309485253"}},"outputId":"12162fbc-1920-45df-8333-720c3f03b8ca"},"source":["def binary_subdivision( class0, class1, train_images, train_labels, test_images, test_labels):\n","  '''\n","  Extract only the two class needed\n","  - class0: labels that becomes 0\n","  - class1: labels that becomes 1\n","  Returns binarized train and test images and labels\n","  '''\n","\n","  binary_train_images = []\n","  binary_train_labels = []\n","  binary_test_images = []\n","  binary_test_labels = []\n","\n","  for train_image, train_label in zip(train_images, train_labels):\n","      if train_label in class0:\n","        binary_train_labels.append(0)\n","        binary_train_images.append(train_image)\n","      if train_label in class1:\n","        binary_train_labels.append(1) \n","        binary_train_images.append(train_image)\n","\n","  for test_image, test_label in zip(test_images, test_labels):\n","      if test_label in class0:\n","        binary_test_labels.append(0)\n","        binary_test_images.append(test_image)\n","      if test_label in class1:\n","        binary_test_labels.append(1) \n","        binary_test_images.append(test_image)\n","\n","  binary_train_images = np.array(binary_train_images)\n","  binary_train_labels = np.array(binary_train_labels)\n","  binary_test_images = np.array(binary_test_images)\n","  binary_test_labels = np.array(binary_test_labels)\n","\n","  return binary_train_images, binary_train_labels, binary_test_images, binary_test_labels\n","\n","print('\"binary_subdivision\" function loaded' )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"binary_subdivision\" function loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UF-c5m0oJ5Nd"},"source":["def split_train_validation(train_images, train_labels, validation_split):\n","  '''\n","  Split dataset in validation and training set and returns them (OBSOLETE)\n","  '''\n","  # Shuffle the data\n","  seed = 711997 \n","  rng = np.random.RandomState(seed)\n","  rng.shuffle(train_images)\n","  rng = np.random.RandomState(seed)\n","  rng.shuffle(train_labels)\n","\n","  # Extract a training & validation split\n","  num_validation_samples = int(validation_split * len(train_labels))\n","  split_val_images = train_images[-num_validation_samples:]\n","  split_train_images = train_images[:-num_validation_samples]\n","  split_val_labels = train_labels[-num_validation_samples:]\n","  split_train_labels = train_labels[:-num_validation_samples]\n","  return split_train_images, split_train_labels, split_val_images, split_val_labels\n","\n","  print('\"split_train_validation\" function loaded' )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WawrEOeituU5"},"source":["def split_train_validation_baseline(train_images, train_labels, validation_split, baselines):\n","  '''\n","  Split dataset in validation and training set and returns them\n","  '''\n","\n","  train_indexes, val_indexes, split_train_labels, split_val_labels = train_test_split(range(train_images.shape[0]), train_labels, test_size=0.2, random_state=171997, stratify=train_labels)\n","  \n","  # Extract a training & validation split\n","  split_val_images = train_images[val_indexes]\n","  split_train_images = train_images[train_indexes]\n","  val_baselines = baselines[val_indexes]\n","  train_baselines = baselines[train_indexes]\n","\n","  return split_train_images, split_train_labels, split_val_images, split_val_labels, val_baselines, train_baselines\n","\n","  print('\"split_train_validation_baseline\" function loaded' )"],"execution_count":null,"outputs":[]}]}